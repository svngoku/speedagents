# DeepAgents - Enhanced Features

This document describes the enhanced features added to the DeepAgents framework based on the roadmap.

## ğŸ¯ Features Implemented

### 1. âœ… Customizable Full System Prompt

The `create_deep_agent` function now supports full customization of system prompts:

```python
from deepagents import create_deep_agent

# Use completely custom system prompt
agent = create_deep_agent(
    tools=[],
    instructions="Base instructions",
    system_prompt="You are a completely custom agent with your own personality.",
    use_default_prompt=False  # Disable default prompt
)

# Or combine instructions with default prompt
agent = create_deep_agent(
    tools=[],
    instructions="Additional instructions",
    use_default_prompt=True  # Appends default prompt (default behavior)
)
```

### 2. âœ… Code Cleanliness

All code now includes:
- **Type Hints**: Complete type annotations for all functions and methods
- **Docstrings**: Comprehensive documentation for all public APIs
- **Formatting**: Code formatted with Black for consistency
- **Better imports**: Organized and explicit imports

Example from `graph.py`:
```python
def create_deep_agent(
    tools: Sequence[Union[BaseTool, Callable, Dict[str, Any]]],
    instructions: str,
    model: Optional[Union[str, LanguageModelLike]] = None,
    subagents: Optional[List[SubAgent]] = None,
    state_schema: Optional[StateSchemaType] = None,
    system_prompt: Optional[str] = None,
    use_default_prompt: bool = True,
    human_in_the_loop: Optional[Callable] = None,
) -> StateGraph:
    """Create a deep agent with enhanced capabilities.
    
    Args:
        tools: The additional tools the agent should have access to.
        instructions: The additional instructions the agent should have.
        model: The model to use. If None, uses the default model.
        subagents: The subagents to use.
        state_schema: The schema of the deep agent.
        system_prompt: Custom system prompt to completely override the default.
        use_default_prompt: Whether to append the default base prompt to instructions.
        human_in_the_loop: Optional callback for human intervention during execution.
    
    Returns:
        StateGraph: A configured LangGraph agent.
    """
```

### 3. âœ… Robust Virtual Filesystem

Enhanced virtual filesystem with:
- **File versioning**: Track changes with version history
- **Metadata support**: Creation time, modification time, permissions, size
- **Directory support**: Create and navigate directories
- **Advanced operations**: Copy files, view history, enhanced listing

New filesystem tools in `filesystem.py`:
- `mkdir`: Create directories
- `cd`: Change directory
- `pwd`: Print working directory
- `ls_enhanced`: List with metadata
- `file_history`: Show version history
- `cp`: Copy files
- `human_input`: Request human input

Example usage:
```python
from deepagents.filesystem import mkdir, cd, pwd, ls_enhanced, file_history

# Use in your agent
agent = create_deep_agent(
    tools=[mkdir, cd, pwd, ls_enhanced, file_history],
    instructions="File management agent"
)
```

### 4. âœ… Deep Coding Agent Example

A comprehensive coding agent example in `examples/coding/coding_agent.py` featuring:
- **Specialized subagents**: Refactoring expert, testing expert, code reviewer
- **Custom coding tools**: Code analysis, refactoring, test generation
- **Human-in-the-loop**: Interactive refactoring reviews
- **Benchmarking support**: Performance measurement

Example:
```python
from examples.coding.coding_agent import create_coding_agent

agent = create_coding_agent()

# The agent includes:
# - Refactoring expert subagent
# - Testing expert subagent  
# - Code review subagent
# - Tools for code analysis and transformation
```

### 5. âœ… Benchmarking Support

Built-in benchmarking capabilities:
- **Tool benchmarking**: Decorator to measure tool execution time
- **Agent benchmarking**: Example implementation in coding agent
- **Performance tracking**: Store benchmarks in agent state

Example:
```python
from deepagents.tools import benchmark_tool_call

@tool
@benchmark_tool_call
def my_tool():
    # Tool implementation
    # Automatically prints: "Benchmark: my_tool took X.XXXXXX seconds."
    pass
```

### 6. âœ… Human-in-the-Loop Support

Multiple levels of human interaction:
- **Callback system**: Pass callbacks to agent creation
- **Human input tool**: Request input during execution
- **Task-level callbacks**: Get notified when tasks start/complete

Example:
```python
def human_callback(event: str, message: str):
    print(f"Event: {event} - Message: {message}")
    # Handle human interaction
    
agent = create_deep_agent(
    tools=[human_input],
    instructions="Interactive agent",
    human_in_the_loop=human_callback
)
```

## ğŸ“ Project Structure

```
deepagents/
â”œâ”€â”€ src/deepagents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ graph.py          # Enhanced agent creation with new features
â”‚   â”œâ”€â”€ model.py          # Model configuration
â”‚   â”œâ”€â”€ state.py          # Enhanced state with virtual filesystem
â”‚   â”œâ”€â”€ tools.py          # Core tools with benchmarking
â”‚   â”œâ”€â”€ filesystem.py     # New filesystem tools
â”‚   â”œâ”€â”€ sub_agent.py      # Enhanced with human-in-the-loop
â”‚   â””â”€â”€ prompts.py        # Prompt templates
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ research/         # Original research example
â”‚   â””â”€â”€ coding/           # New coding agent example
â”‚       â””â”€â”€ coding_agent.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/
â”‚       â”œâ”€â”€ test_graph.py # Unit tests for graph module
â”‚       â””â”€â”€ test_state.py # Unit tests for state module
â””â”€â”€ pyproject.toml
```

## ğŸš€ Getting Started

1. Install the package:
```bash
pip install -e .
```

2. Run tests:
```bash
pytest tests/
```

3. Try the coding agent example:
```python
from examples.coding.coding_agent import example_coding_task
import asyncio

asyncio.run(example_coding_task())
```

## ğŸ”§ Configuration Options

The enhanced `create_deep_agent` supports:
- Custom system prompts
- Multiple subagents with specialized roles
- Human-in-the-loop callbacks
- Enhanced state management
- Virtual filesystem with versioning
- Benchmarking and performance tracking

## ğŸ“ˆ Future Enhancements

Potential areas for further development:
- Real filesystem integration
- Distributed agent execution
- More sophisticated benchmarking
- Enhanced human interaction UI
- Agent communication protocols
- Persistent state management
